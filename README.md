# REST API Downloader

High-performance web service for programmatic URL content downloading with intelligent article extraction.

## üöÄ Features

- **Direct URL Access**: Simple `/{url}` endpoint structure
- **Background Batch Processing**: Asynchronous job-based processing with progress tracking
- **Content Negotiation**: Multiple response formats via Accept headers
- **PDF Generation**: JavaScript-rendered PDFs using Playwright
- **API Key Protection**: Optional authentication via environment variable
- **Intelligent Extraction**: BeautifulSoup-powered article text extraction
- **Security**: SSRF protection and URL validation
- **Performance**: Async HTTP client with connection pooling
- **Production Ready**: Docker support with health checks
- **Comprehensive Testing**: 100% test coverage for critical components

## üìã API Endpoints

### Health Check
```http
GET /health
```
Returns service health status and version.

### URL Download with Content Negotiation
```http
GET /{url}
Accept: {format}
```

**Supported Accept Header Formats:**

| Accept Header | Response Type | Description |
|---------------|---------------|-------------|
| `text/plain` | Plain Text | Extracted article content, clean text only |
| `text/markdown` | Markdown | Structured markdown with headings and links |
| `text/html` | HTML | Original HTML content |
| `application/pdf` | PDF | JavaScript-rendered PDF via Playwright |
| `application/json` | JSON | Base64 content with metadata |
| *No Accept header* | **Plain Text (Default)** | **Default format returns extracted article text** |

### Background Batch Processing

Submit jobs for processing multiple URLs asynchronously with progress tracking.

#### Submit Batch Job
```http
POST /batch
Content-Type: application/json

{
  "urls": [
    {"url": "https://example.com", "format": "text"},
    {"url": "https://github.com", "format": "markdown"}
  ],
  "default_format": "text",
  "concurrency_limit": 10,
  "timeout_per_url": 30
}
```

Returns job ID for tracking progress and retrieving results.

#### Check Job Status
```http
GET /jobs/{job_id}/status
```

Returns current job status, progress percentage, and processing statistics.

#### Download Results
```http
GET /jobs/{job_id}/results
```

Downloads complete job results as JSON when processing is finished.

#### Cancel Job
```http
DELETE /jobs/{job_id}
```

Cancels a running or pending job.

## üîê Authentication

API key authentication is **optional** and controlled by the `DOWNLOADER_KEY` environment variable.

### Without Authentication (Default)
If `DOWNLOADER_KEY` is not set, all endpoints are publicly accessible:

```bash
curl -H "Accept: text/plain" http://localhost:8000/https://example.com
```

### With Authentication
Set the `DOWNLOADER_KEY` environment variable to enable API key protection:

```bash
# Start server with authentication
DOWNLOADER_KEY=your-secret-key uv run python run.py
```

Once enabled, provide the API key using any of these methods:

**1. Bearer Token (Recommended)**
```bash
curl -H "Authorization: Bearer your-secret-key" \
     -H "Accept: text/plain" \
     http://localhost:8000/https://example.com
```

**2. X-API-Key Header**
```bash
curl -H "X-API-Key: your-secret-key" \
     -H "Accept: text/plain" \
     http://localhost:8000/https://example.com
```


### Authentication Status
Check if authentication is enabled via the health endpoint:

```bash
curl http://localhost:8000/health
```

Returns authentication status and supported methods when enabled.

## üî• Quick Start

### Using Docker (Recommended)

```bash
# Build the image
docker build -t downloader .

# Run without authentication
docker run -p 8000:8000 downloader

# Or run with API key authentication
docker run -e DOWNLOADER_KEY=your-secret-key -p 8000:8000 downloader

# Test the API
curl -H "Accept: text/plain" http://localhost:8000/https://example.com
```

### Local Development

```bash
# Install dependencies
uv sync

# Run development server
uv run python run.py

# Run tests
uv run pytest tests/ -v
```

## üìñ Usage Examples

### Extract Article Text
```bash
curl -H "Accept: text/plain" \
  "http://localhost:8000/https://news.ycombinator.com"
```

### Get Markdown Format
```bash
curl -H "Accept: text/markdown" \
  "http://localhost:8000/https://github.com/python/cpython"
```

### Get JSON with Metadata
```bash
curl -H "Accept: application/json" \
  "http://localhost:8000/https://httpbin.org/json" | jq
```

### Get Original HTML
```bash
curl -H "Accept: text/html" \
  "http://localhost:8000/https://example.com"
```

## üõ°Ô∏è Security Features

- **SSRF Protection**: Blocks localhost and private IP ranges (configurable)
- **URL Validation**: Comprehensive input sanitization
- **Rate Limiting**: Multi-tier limits with Redis/in-memory storage (NEW)
  - Download endpoints: 60 requests/minute
  - Batch endpoints: 20 requests/minute
  - Status endpoints: 200 requests/minute
- **API Key Authentication**: Optional Bearer token or X-API-Key header
- **Non-root Container**: Docker runs with dedicated user account
- **DoS Protection**: Configurable concurrency limits and timeouts

## üß™ Testing

The project uses a 3-tier test strategy for fast CI/CD:

```bash
# Quick smoke tests (<3s) - for rapid feedback
uv run pytest -m smoke -v

# Integration tests (~15s) - for component testing
uv run pytest -m integration -v

# Full E2E tests (~60s) - for comprehensive validation
uv run pytest -m e2e -v

# Run all tests with coverage
uv run pytest --cov=src --cov-report=html

# Test specific functionality
uv run pytest tests/api/test_download.py -v
```

**Test Statistics**: 248 tests (80 smoke, organized into smoke/integration/e2e tiers)

## üèóÔ∏è Architecture

- **FastAPI**: Modern async web framework
- **httpx**: High-performance HTTP client
- **BeautifulSoup**: Intelligent HTML parsing and article extraction
- **Pydantic**: Data validation and serialization
- **Docker**: Production-ready containerization

## üìà Performance

- **Async Support**: Non-blocking I/O operations
- **Connection Pooling**: Efficient HTTP connection reuse
- **Smart Extraction**: Targets main content areas (`<article>`, `<main>`, etc.)
- **Memory Efficient**: Streaming support for large files

## üîß Configuration

The service is configured via environment variables with sensible defaults:

### Core Settings
- `DOWNLOADER_KEY`: API key for authentication (optional)
- `REDIS_URI`: Redis connection string for job management and rate limiting
- `ENVIRONMENT`: Runtime environment (development/staging/production)

### HTTP Client
- `HTTP_MAX_CONNECTIONS`: Max total connections (default: 200)
- `HTTP_REQUEST_TIMEOUT`: Request timeout in seconds (default: 30)

### Rate Limiting (NEW)
- `RATELIMIT_ENABLED`: Enable rate limiting (default: true)
- `RATELIMIT_DEFAULT_LIMIT`: Default limit (default: "100/minute")
- `RATELIMIT_DOWNLOAD_LIMIT`: Download endpoint limit (default: "60/minute")
- `RATELIMIT_BATCH_LIMIT`: Batch job limit (default: "20/minute")

### Batch Processing
- `BATCH_CONCURRENCY`: Max concurrent batch requests (default: CPU√ó8, max 50)
- `BATCH_MAX_URLS_PER_BATCH`: Max URLs per batch (default: 50)

### PDF Generation
- `PDF_CONCURRENCY`: Max concurrent PDFs (default: CPU√ó2, max 12)
- `PDF_PAGE_LOAD_TIMEOUT`: Playwright timeout in ms (default: 30000)

### Security
- `SSRF_BLOCK_PRIVATE_IPS`: Block private IPs (default: true)
- `CORS_ALLOWED_ORIGINS`: Comma-separated origins (default: "*")

See `.env.example` for complete configuration reference.

## üì¶ Implementation Status

**‚úÖ Production Ready Features:**
- ‚úÖ Direct URL endpoint structure (`/{url}`)
- ‚úÖ Content negotiation via Accept headers (text, markdown, HTML, JSON, PDF)
- ‚úÖ Background batch processing with job tracking
- ‚úÖ PDF generation with Playwright
- ‚úÖ **Rate limiting with DoS protection** (NEW)
- ‚úÖ Comprehensive test suite (248 tests: 80 smoke, 3-tier strategy)
- ‚úÖ SSRF protection and URL validation
- ‚úÖ Optional API key authentication
- ‚úÖ Production-ready Docker container
- ‚úÖ Structured logging with JSON support
- ‚úÖ Comprehensive configuration management (40+ settings)
- ‚úÖ Health check and metrics endpoints

**üöß Roadmap (Next Steps):**
- üü† High Priority (7-11 hours): HTTP client simplification, memory leak fixes, Docker improvements
- üü° Performance (2-4 weeks): Redis caching, webhook notifications, OpenTelemetry
- üü¢ Advanced (1-2 months): Enhanced content preprocessing, SDK libraries, GraphQL API
- üîµ Enterprise (3-6 months): OAuth2/JWT, multi-region deployment, AI-powered extraction

See `product/roadmap.md` for detailed implementation timeline.
